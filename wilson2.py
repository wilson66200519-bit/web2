import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urljoin, urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (æ­»çºçˆ›æ‰“ç‰ˆ)", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ å…¨è‡ªå‹•å®¢æˆ¶åå–®æœé›†å™¨ (äºŒæ¬¡è¿½æ®ºè£œå®Œç‰ˆ)")
st.markdown("""
### ğŸš€ æ—¢ç„¶ä¸æ»¿æ„ï¼Œæˆ‘å€‘å°±è¿½åˆ°åº•ï¼š
é€™å€‹ç‰ˆæœ¬åŠ å…¥äº† **ã€ŒäºŒæ¬¡è¿½æ®º (Double-Tap)ã€** æ©Ÿåˆ¶ã€‚
å¦‚æœç¬¬ä¸€æ¬¡çˆ¬å®Œå®˜ç¶²ç™¼ç¾ **æ²’æœ‰ Email**ï¼Œç¨‹å¼æœƒè‡ªå‹•ç™¼èµ·ç¬¬äºŒæ¬¡ç²¾ç¢ºæœå°‹ï¼š
`"{å…¬å¸å} email è¯çµ¡"`
ç›´æ¥å¾ç¶²è·¯ä¸ŠæŠŠå®ƒçš„ Email é€¼å‡ºä¾†ï¼
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    if "GEMINI_API_KEY" in st.secrets:
        gemini_api_key = st.secrets["GEMINI_API_KEY"]
        st.success("âœ… å·²è®€å– Gemini Key")
    else:
        gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")

    if "TAVILY_API_KEY" in st.secrets:
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
        st.success("âœ… å·²è®€å– Tavily Key")
    else:
        tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")

    num_results = st.slider("æœå°‹æ•¸é‡", 3, 20, 5) 
    debug_mode = st.toggle("é¡¯ç¤ºå¾Œå°è™•ç†éç¨‹", value=True)

# --- 3. æ ¸å¿ƒå·¥å…· ---

def get_root_url(url):
    """ å¼·åˆ¶è½‰å›é¦–é  """
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def find_contact_link(markdown_text, root_url):
    """ å°‹æ‰¾å…§é é€£çµ """
    links = re.findall(r'\[(.*?)\]\((.*?)\)', markdown_text)
    keywords = [
        "è¯çµ¡", "contact", "about", "é—œæ–¼", "support", "inquiry", "è©¢åƒ¹", 
        "æœå‹™", "service", "map", "location", "æ“šé»", "ç‡Ÿæ¥­", "profile", "ç°¡ä»‹"
    ]
    for text, link in links:
        for kw in keywords:
            if kw in text.lower():
                full_link = urljoin(root_url, link)
                return full_link, text
    return None, None

def fetch_content_smart(url, fallback_content=""):
    """ æ™ºæ…§æŠ“å–æµç¨‹ """
    if fallback_content is None: fallback_content = ""
    combined_content = ""
    source_log = []
    root_url = get_root_url(url)
    jina_url = f"https://r.jina.ai/{root_url}"
    
    try:
        resp = requests.get(jina_url, timeout=10)
        if resp.status_code == 200 and len(resp.text) > 200:
            homepage_text = resp.text
            combined_content += f"\n=== é¦–é å…§å®¹ ===\n{homepage_text[:20000]}"
            source_log.append("é¦–é ")
            if "@" not in homepage_text:
                contact_link, link_text = find_contact_link(homepage_text, root_url)
                if contact_link:
                    source_log.append(f"å…§é ({link_text})")
                    jina_contact_url = f"https://r.jina.ai/{contact_link}"
                    resp_inner = requests.get(jina_contact_url, timeout=10)
                    if resp_inner.status_code == 200:
                        combined_content += f"\n=== {link_text} ===\n{resp_inner.text[:20000]}"
        else:
            if len(fallback_content) > 50:
                combined_content = fallback_content
                source_log.append("åº«å­˜")
    except:
        if len(fallback_content) > 50:
            combined_content = fallback_content
            source_log.append("åº«å­˜(æ•‘æ´)")

    return combined_content, " + ".join(source_log)

def regex_heavy_duty(text):
    """ å¼·åŠ›æƒæ + æ™ºæ…§åˆ†é¡ """
    if not text: return [], [], [], []
    text_clean = " ".join(text.split())
    
    # Email
    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
    mailto_emails = re.findall(r'mailto:([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', text)
    all_emails = list(set(emails + mailto_emails))

    # Fax
    fax_patterns = [
        r'(?:Fax|FAX|å‚³çœŸ|Facsimile|F\.|F:)[\s:ï¼š\.]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})',
        r'(?:Tel\/Fax|TEL\/FAX)[\s:ï¼š\.]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})'
    ]
    faxes = []
    for pattern in fax_patterns:
        found = re.findall(pattern, text)
        faxes.extend(found)
    faxes = list(set(faxes))
    
    # Phone / Tax ID
    raw_numbers = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
    phones = []
    tax_ids = []
    for num in list(set(raw_numbers)):
        clean_num = re.sub(r'\D', '', num)
        is_fax = False
        for f in faxes:
            if clean_num in re.sub(r'\D', '', f):
                is_fax = True; break
        if is_fax: continue

        if len(clean_num) >= 8:
            if clean_num.startswith('0'): phones.append(num)
            elif len(clean_num) == 8: tax_ids.append(clean_num)
            else: phones.append(num)

    return all_emails, phones, faxes, tax_ids

# --- 4. è£œåˆ€æœå°‹åŠŸèƒ½ (Hunter Mode) ---
def hunter_search(company_name, tavily_client):
    """ ç•¶ç¼ºè³‡æ–™æ™‚ï¼Œå°ˆé–€é‡å°è©²å…¬å¸é€²è¡Œç²¾ç¢ºæœå°‹ """
    if not company_name or company_name == "Unknown": return ""
    
    # æœå°‹ç­–ç•¥ï¼šå…¬å¸å + email
    query = f"{company_name} email è¯çµ¡æ–¹å¼ contact"
    try:
        # åªæŠ“å‰ 3 ç­†çµæœçš„æ‘˜è¦å°±å¥½ï¼Œä¸ç”¨é€²å»çˆ¬
        resp = tavily_client.search(query=query, max_results=3)
        snippets = ""
        for res in resp.get('results', []):
            snippets += res.get('content', '') + "\n"
        return snippets
    except:
        return ""

# --- 5. AI åˆ†æå‡½æ•¸ ---

def extract_contact_info(content, url, model, snippet_content="", company_name_hint=""):
    full_scan_text = content + "\n=== æœå°‹æ‘˜è¦ ===\n" + snippet_content
    emails, phones, faxes, tax_ids = regex_heavy_duty(full_scan_text)
    
    try:
        backup_info = f"Email: {emails[:3]}, é›»è©±: {phones[:3]}, å‚³çœŸ: {faxes[:2]}"
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–æ©Ÿå™¨äººã€‚è«‹æ‰¾å‡ºè¯çµ¡æ–¹å¼ã€‚
        ç›®æ¨™å…¬å¸ï¼š{company_name_hint}
        
        ç¶²å€ï¼š{url}
        åƒè€ƒæ•¸æ“šï¼š{backup_info}
        
        ç¶²é å…§å®¹èˆ‡æ‘˜è¦ï¼š
        {content[:30000]} 
        {snippet_content}
        
        è«‹å›å‚³ JSONï¼š
        {{
            "å…¬å¸åç¨±": "...", 
            "é›»è©±": "...", 
            "Email": "...",
            "å‚³çœŸ": "...",
            "ç¶²å€": "{url}"
        }}
        """
        response = model.generate_content(prompt)
        txt = response.text.strip()
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt: txt = txt.split("```")[0]
        data = json.loads(txt)

        # å¼·åŠ›å›å¡«
        if (not data.get("Email") or str(data.get("Email")).lower() in ["none", "", "null"]) and emails:
            data["Email"] = ", ".join(emails[:2])
        if (not data.get("é›»è©±") or str(data.get("é›»è©±")).lower() in ["none", "", "null"]) and phones:
            data["é›»è©±"] = ", ".join(phones[:2])
        if (not data.get("å‚³çœŸ") or str(data.get("å‚³çœŸ")).lower() in ["none", "", "null"]) and faxes:
            data["å‚³çœŸ"] = faxes[0]
        if tax_ids:
            data["çµ±ç·¨"] = ", ".join(tax_ids[:1])
        else:
            data["çµ±ç·¨"] = ""

        return data
    except:
        return {
            "å…¬å¸åç¨±": "ERROR", 
            "é›»è©±": ", ".join(phones[:2]), 
            "Email": ", ".join(emails[:2]), 
            "å‚³çœŸ": faxes[0] if faxes else "",
            "çµ±ç·¨": ", ".join(tax_ids[:1]),
            "ç¶²å€": url
        }

# --- 6. ä¸»ç¨‹å¼ ---
keyword = st.text_input("ğŸ” è«‹è¼¸å…¥æœå°‹é—œéµå­—", value="å»¢æ°´å›æ”¶ç³»çµ± å…¬å¸")

if st.button("é–‹å§‹æœå°‹èˆ‡åˆ†æ"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹è¼¸å…¥ API Key")
    else:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        tavily = TavilyClient(api_key=tavily_api_key)
        
        status_box = st.status("ğŸš€ å•Ÿå‹•æ­»çºçˆ›æ‰“æ¨¡å¼...", expanded=True)
        results_list = []
        
        try:
            status_box.write(f"æ­£åœ¨æœå°‹ï¼š{keyword}...")
            response = tavily.search(query=keyword, max_results=num_results, include_raw_content=True)
            search_results = response.get('results', [])
            
            if not search_results:
                status_box.error("æ‰¾ä¸åˆ°ç¶²å€")
            else:
                progress_bar = st.progress(0)
                
                for i, item in enumerate(search_results):
                    try:
                        url = item.get('url', 'ç„¡ç¶²å€')
                        title = item.get('title', 'ç„¡æ¨™é¡Œ')
                        tavily_raw = item.get('raw_content') or ""
                        tavily_snippet = item.get('content') or ""
                        
                        status_box.write(f"({i+1}/{len(search_results)}) åˆ†æï¼š{title}")
                        
                        # 1. æ­£å¸¸çˆ¬å–
                        content, source_log = fetch_content_smart(url, fallback_content=tavily_raw)
                        data = extract_contact_info(content, url, model, snippet_content=tavily_snippet, company_name_hint=title)
                        
                        # ä¿®å¾©å…¬å¸åç¨±
                        name = str(data.get("å…¬å¸åç¨±", ""))
                        if name in ["ERROR", "None"] or "å¤±æ•—" in name:
                            name = title
                            data["å…¬å¸åç¨±"] = title

                        # 2. [é—œéµè£œåˆ€] å¦‚æœ Email é‚„æ˜¯ç©ºçš„ï¼Œç™¼å‹•äºŒæ¬¡æœå°‹
                        current_email = str(data.get("Email", ""))
                        if not current_email or current_email.lower() in ["none", "", "null"]:
                            if debug_mode: status_box.write(f"âš ï¸ {title} æ²’æŠ“åˆ° Emailï¼Œç™¼å‹•è£œåˆ€æœå°‹...")
                            
                            # è£œåˆ€æœå°‹ (Targeted Search)
                            hunter_snippet = hunter_search(name, tavily)
                            
                            # å†æ¬¡ç”¨ Regex å¾è£œåˆ€çµæœæŠ“è³‡æ–™
                            new_emails, _, _, _ = regex_heavy_duty(hunter_snippet)
                            
                            if new_emails:
                                data["Email"] = ", ".join(new_emails[:2])
                                data["å‚™è¨»"] = "äºŒæ¬¡è£œåˆ€æˆåŠŸ" # è®“ä½ çœ‹åˆ°æ•ˆæœ
                                if debug_mode: status_box.write(f"âœ… è£œåˆ€æˆåŠŸï¼æŠ“åˆ°: {new_emails[0]}")
                        
                        results_list.append(data)
                            
                    except Exception as e:
                        if debug_mode: st.warning(f"è™•ç† {title} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        pass
                        
                    progress_bar.progress((i + 1) / len(search_results))
                    time.sleep(1)

                status_box.update(label="ğŸ‰ æœé›†å®Œæˆï¼", state="complete", expanded=False)
                
                if results_list:
                    df = pd.DataFrame(results_list)
                    cols = ["å…¬å¸åç¨±", "çµ±ç·¨", "é›»è©±", "Email", "å‚³çœŸ", "ç¶²å€", "å‚™è¨»"]
                    
                    for c in cols:
                        if c not in df.columns: df[c] = ""
                    df = df[cols]

                    st.dataframe(df)
                    excel_file = "leads_hunter.xlsx"
                    df.to_excel(excel_file, index=False)
                    with open(excel_file, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel åå–®", f, file_name=f"{keyword}_æ­»çºçˆ›æ‰“ç‰ˆ.xlsx")

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")