import streamlit as st
import google.generativeai as genai
import requests
import pandas as pd
import json
import time
from googlesearch import search  

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ Google å…¨è‡ªå‹•å®¢æˆ¶åå–®æœé›†å™¨")
st.markdown("è¼¸å…¥é—œéµå­— (ä¾‹å¦‚ï¼š`å°åŒ— å®¤å…§è¨­è¨ˆå…¬å¸`)ï¼ŒAI è‡ªå‹•å¹«ä½ æœé›†å‰ 10 å®¶å…¬å¸çš„è¯çµ¡æ–¹å¼ã€‚")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    user_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")
    num_results = st.slider("è¦æŠ“å¹¾å®¶å…¬å¸ï¼Ÿ", 5, 20, 10)
    
    st.info("ğŸ’¡ è²¼å¿ƒæé†’ï¼šæŠ“å¤ªå¤šå®¶å¯èƒ½æœƒè¢« Google æš«æ™‚æ“‹ä½ IPï¼Œå»ºè­°ä¸€æ¬¡ 10 å®¶å·¦å³ã€‚")

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

# A. ç”¨ AI åˆ†æç¶²é å…§å®¹ (é€™æ˜¯ä½ çš„å¼·é …ï¼Œæˆ‘å€‘æ²¿ç”¨)
def extract_contact_info(html_text, url, model):
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹è³‡æ–™æ¢å‹˜å°ˆå®¶ã€‚è«‹å¾ä¸‹æ–¹çš„ HTML åŸå§‹ç¢¼ä¸­ï¼Œæå–é€™å®¶å…¬å¸çš„è¯çµ¡è³‡è¨Šã€‚
    
    ç›®æ¨™ç¶²å€ï¼š{url}
    
    è«‹å°‹æ‰¾ä»¥ä¸‹æ¬„ä½ï¼š
    1. å…¬å¸åç¨± (Company Name) - å¦‚æœæ‰¾ä¸åˆ°ï¼Œç”¨ç¶²é æ¨™é¡Œæˆ–ç¶²å€æ¨æ¸¬
    2. é›»è©± (Phone)
    3. å‚³çœŸ (Fax) - å¦‚æœæ²’æœ‰å°±ç•™ç©º
    4. Email - å¦‚æœæ²’æœ‰å°±ç•™ç©º
    5. ç¶²å€ (URL) - å›å‚³ï¼š{url}
    
    HTML å…§å®¹æ‘˜è¦ï¼š{html_text[:50000]} 
    
    è«‹åš´æ ¼å›å‚³ JSON æ ¼å¼ï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    {{
        "å…¬å¸åç¨±": "...",
        "ç¶²å€": "...",
        "é›»è©±": "...",
        "å‚³çœŸ": "...",
        "Email": "..."
    }}
    """
    try:
        response = model.generate_content(prompt)
        # æ¸…ç† AI å›å‚³çš„æ ¼å¼
        clean_json = response.text.strip().replace('```json', '').replace('```', '')
        return json.loads(clean_json)
    except Exception as e:
        return {"å…¬å¸åç¨±": "è§£æå¤±æ•—", "ç¶²å€": url, "éŒ¯èª¤è¨Šæ¯": str(e)}

# B. çˆ¬å–å–®ä¸€ç¶²é 
def fetch_page_content(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = response.apparent_encoding
        return response.text
    except:
        return None

# --- 4. ä¸»ç¨‹å¼é‚è¼¯ ---
keyword = st.text_input("ğŸ” è«‹è¼¸å…¥æœå°‹é—œéµå­—", placeholder="ä¾‹å¦‚ï¼šå°ä¸­ ç²¾å¯†æ©Ÿæ¢°å» ")

if st.button("é–‹å§‹æœå°‹èˆ‡åˆ†æ"):
    if not user_api_key:
        st.error("âŒ è«‹å…ˆåœ¨å·¦å´è¼¸å…¥ Gemini API Key")
    elif not keyword:
        st.warning("âš ï¸ è«‹è¼¸å…¥é—œéµå­—")
    else:
        # è¨­å®š AI
        genai.configure(api_key=user_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        status_box = st.status("ğŸš€ ä»»å‹™å•Ÿå‹•ä¸­...", expanded=True)
        results_list = []
        
        # --- ç¬¬ä¸€éšæ®µï¼šGoogle æœå°‹ ---
        status_box.write(f"æ­£åœ¨ Google ä¸Šæœå°‹ï¼š{keyword}...")
        try:
            # lang='zh-TW' ç¢ºä¿æœå°‹çµæœæ˜¯ç¹é«”ä¸­æ–‡å„ªå…ˆ
            # advanced=True æœƒå›å‚³æ›´å¤šè³‡è¨Šï¼Œä½†æˆ‘å€‘é€™è£¡åªéœ€è¦ç¶²å€ï¼Œç”¨é è¨­å³å¯
            search_results = list(search(keyword, num_results=num_results, lang="zh-TW"))
            
            status_box.write(f"âœ… æ‰¾åˆ° {len(search_results)} å€‹ç¶²å€ï¼Œæº–å‚™é–‹å§‹é€ä¸€åˆ†æ...")
            
            # å»ºç«‹é€²åº¦æ¢
            progress_bar = st.progress(0)
            
            # --- ç¬¬äºŒéšæ®µï¼šé€ä¸€çˆ¬å– ---
            for i, url in enumerate(search_results):
                status_box.write(f"({i+1}/{len(search_results)}) æ­£åœ¨åˆ†æï¼š{url}")
                
                # 1. æŠ“ç¶²é 
                html_content = fetch_page_content(url)
                
                if html_content:
                    # 2. AI æå–
                    data = extract_contact_info(html_content, url, model)
                    results_list.append(data)
                else:
                    # å¦‚æœç¶²é æ‰“ä¸é–‹ (æœ‰äº›å…¬å¸æ“‹çˆ¬èŸ²)
                    results_list.append({
                        "å…¬å¸åç¨±": "ç„¡æ³•è®€å–ç¶²é ",
                        "ç¶²å€": url,
                        "é›»è©±": "", "å‚³çœŸ": "", "Email": ""
                    })
                
                # æ›´æ–°é€²åº¦æ¢
                progress_bar.progress((i + 1) / len(search_results))
                
                # é‡è¦ï¼šä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…å°åˆ¥äººçš„ç¶²ç«™é€ æˆè² æ“” (ä¹Ÿé¿å…è¢« Google å°é–)
                time.sleep(1)

            status_box.update(label="ğŸ‰ åˆ†æå®Œæˆï¼", state="complete", expanded=False)
            
            # --- 5. é¡¯ç¤ºçµæœèˆ‡åŒ¯å‡º ---
            if results_list:
                df = pd.DataFrame(results_list)
                
                st.subheader("ğŸ“Š æœå°‹çµæœ")
                st.dataframe(df)
                
                # è£½ä½œ Excel ä¸‹è¼‰
                excel_file = "leads_data.xlsx"
                df.to_excel(excel_file, index=False)
                
                with open(excel_file, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ Excel åå–®",
                        data=f,
                        file_name=f"{keyword}_å®¢æˆ¶åå–®.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            st.warning("å¦‚æœæ˜¯ '429 Too Many Requests'ï¼Œä»£è¡¨æœå°‹å¤ªå¿«è¢« Google æ“‹ä½äº†ï¼Œè«‹ä¼‘æ¯å¹¾åˆ†é˜å†è©¦ã€‚")