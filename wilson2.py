import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urljoin, urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (æœ€çµ‚é‡ç”¢ç‰ˆ)", layout="wide")
st.title("ğŸ­ å…¨è‡ªå‹•å®¢æˆ¶åå–®å·¥å»  (æœ€çµ‚é‡ç”¢ç‰ˆ)")
st.markdown("""
### ğŸ›¡ï¸ ç³»çµ±å°±ç·’ï¼š
1. **é›™é‡è³‡æ–™æº**ï¼šå„ªå…ˆä½¿ç”¨ Jina å³æ™‚çˆ¬èŸ²ï¼Œå¤±æ•—æ™‚è‡ªå‹•åˆ‡æ›è‡³ Tavily æœå°‹åº«å­˜ã€‚
2. **æ ¼å¼ä¿è­‰**ï¼šè¼¸å‡º **CSV (UTF-8 BOM)**ï¼ŒExcel é–‹å•Ÿä¸äº‚ç¢¼ï¼Œç„¡éœ€é¡å¤–å¥—ä»¶ã€‚
3. **é•·æ•ˆåŸ·è¡Œ**ï¼šå„ªåŒ–è¨˜æ†¶é«”èˆ‡é€Ÿç‡é™åˆ¶ï¼Œé©åˆåŸ·è¡Œ 500+ ç­†çš„å¤§å‹ä»»å‹™ã€‚
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ API è¨­å®š")
    
    # å„ªå…ˆè®€å– Secretsï¼Œè‹¥ç„¡å‰‡é¡¯ç¤ºè¼¸å…¥æ¡†
    try:
        gemini_api_key = st.secrets["GEMINI_API_KEY"]
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
        st.success("âœ… API Key å·²å¾ Secrets è¼‰å…¥")
    except:
        gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")
        tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")
    
    st.divider()
    st.header("ğŸ¯ ç›®æ¨™è¨­å®š")
    target_amount = st.slider("ç›®æ¨™è³‡æ–™ç­†æ•¸", 10, 1000, 50, step=10)
    enable_hunter = st.toggle("é–‹å•Ÿã€Œè£œåˆ€è¿½æ®ºã€ (ç¼ºè³‡æ–™æ™‚è‡ªå‹•æœç¬¬äºŒæ¬¡)", value=True)
    debug_mode = st.toggle("é¡¯ç¤ºé™¤éŒ¯è¨Šæ¯", value=False)

# --- 3. æ ¸å¿ƒå·¥å…·å‡½æ•¸ ---

def get_root_url(url):
    """ å¼·åˆ¶è½‰å›é¦–é ï¼Œæé«˜è¯çµ¡è³‡è¨Šå‘½ä¸­ç‡ """
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def fetch_content_robust(url, fallback_content=""):
    """ 
    å¼·éŸŒçš„çˆ¬å–æµç¨‹ï¼š
    1. å˜—è©¦ Jina AI (é–±è®€æ¨¡å¼)
    2. å¤±æ•—å‰‡ä½¿ç”¨ Tavily çš„åº«å­˜ (fallback_content)
    """
    combined_content = ""
    source_log = []
    root_url = get_root_url(url)
    
    # å˜—è©¦ 1: Jina AI
    jina_url = f"https://r.jina.ai/{root_url}"
    try:
        # è¨­å®š User-Agent é¿å…è¢«æŸäº›ç¶²ç«™ç›´æ¥æ“‹
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(jina_url, headers=headers, timeout=8)
        
        if resp.status_code == 200 and len(resp.text) > 100:
            combined_content += f"\n=== Jinaå³æ™‚çˆ¬å– ===\n{resp.text[:15000]}"
            source_log.append("å³æ™‚çˆ¬èŸ²")
        else:
            raise Exception("Jina content too short or blocked")
            
    except Exception as e:
        # å¤±æ•—æ™‚ä½¿ç”¨å‚™ä»½ (Tavily Raw Content) - é€™æ˜¯é˜²æ­¢ç©ºç™½çš„é—œéµ
        if fallback_content and len(fallback_content) > 50:
            combined_content += f"\n=== æœå°‹å¼•æ“åº«å­˜ ===\n{fallback_content[:15000]}"
            source_log.append("åº«å­˜æ•‘æ´")
        else:
            source_log.append("æŠ“å–å¤±æ•—")

    return combined_content, " + ".join(source_log)

def regex_heavy_duty(text):
    """ æ­£å‰‡è¡¨é”å¼å¼·åŠ›æƒæ (é›»è©±ã€Emailã€å‚³çœŸã€çµ±ç·¨) """
    if not text: return [], [], [], []
    
    # ç§»é™¤éå¤šç©ºç™½
    text_clean = " ".join(text.split())
    
    # Email
    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
    mailto_emails = re.findall(r'mailto:([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', text)
    all_emails = list(set(emails + mailto_emails))

    # å‚³çœŸ (Fax) é—œéµå­—åµæ¸¬
    fax_patterns = [
        r'(?:Fax|FAX|å‚³çœŸ|F\.|F:)[\s:ï¼š\.]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})'
    ]
    faxes = []
    for pattern in fax_patterns:
        found = re.findall(pattern, text)
        faxes.extend(found)
    faxes = list(set(faxes))
    
    # é›»è©±èˆ‡çµ±ç·¨
    raw_numbers = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
    phones = []
    tax_ids = []
    
    for num in list(set(raw_numbers)):
        clean_num = re.sub(r'\D', '', num)
        # æ’é™¤å‚³çœŸ
        is_fax = False
        for f in faxes:
            if clean_num in re.sub(r'\D', '', f):
                is_fax = True; break
        if is_fax: continue

        if len(clean_num) == 8 and not clean_num.startswith('0'):
            tax_ids.append(clean_num)
        elif len(clean_num) >= 8:
            phones.append(num)

    return all_emails, phones, faxes, tax_ids

def hunter_search(company_name, tavily_client):
    """ è£œåˆ€æœå°‹ï¼šé‡å°ç‰¹å®šå…¬å¸æ‰¾è¯çµ¡æ–¹å¼ """
    if not company_name or len(company_name) < 2: return ""
    query = f"{company_name} å°ç£ é›»è©± email è¯çµ¡æ–¹å¼ contact"
    try:
        resp = tavily_client.search(query=query, max_results=3, search_depth="advanced")
        snippets = ""
        for res in resp.get('results', []):
            snippets += res.get('content', '') + "\n"
        return snippets
    except:
        return ""

def extract_contact_info(content, url, model, company_name_hint=""):
    """ Gemini AI èƒå– """
    # 1. å…ˆç”¨ Regex æƒä¸€éï¼Œç¢ºä¿ AI å¤±æ•—æ™‚æœ‰ä¿åº•è³‡æ–™
    emails, phones, faxes, tax_ids = regex_heavy_duty(content)
    backup_info = f"é æƒæ -> Email:{emails[:1]}, é›»è©±:{phones[:1]}"
    
    # 2. å»ºæ§‹ Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„è³‡æ–™æå–å°ˆå®¶ã€‚
    ç›®æ¨™ï¼šæ‰¾å‡º "{company_name_hint}" çš„è¯çµ¡è³‡è¨Šã€‚
    ç¶²å€ï¼š{url}
    åƒè€ƒ(æ­£å‰‡é æƒ)ï¼š{backup_info}
    
    ç¶²é å…§å®¹æ‘˜è¦ï¼š
    {content[:25000]} 
    
    è«‹å›å‚³ç´” JSON æ ¼å¼ (ä¸è¦ Markdown)ï¼š
    {{
        "å…¬å¸åç¨±": "{company_name_hint}", 
        "é›»è©±": "...", 
        "Email": "...",
        "å‚³çœŸ": "...",
        "çµ±ç·¨": "...",
        "å‚™è¨»": "..."
    }}
    æ³¨æ„ï¼šè‹¥æ‰¾ä¸åˆ°ï¼Œè«‹å„ªå…ˆä½¿ç”¨ã€Œåƒè€ƒã€ä¸­çš„æ•¸æ“šã€‚è‹¥éƒ½ç„¡å‰‡ç•™ç©ºã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        txt = response.text.strip()
        # æ¸…æ´— JSON æ¨™è¨˜
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt: txt = txt.split("```")[0]
        data = json.loads(txt)
        
        # 3. å¼·åŠ›å›å¡« (å¦‚æœ AI æ¼æŠ“ï¼Œå¼·åˆ¶è£œä¸Š Regex æŠ“åˆ°çš„)
        if not data.get("Email") and emails: data["Email"] = emails[0]
        if not data.get("é›»è©±") and phones: data["é›»è©±"] = phones[0]
        if not data.get("å‚³çœŸ") and faxes: data["å‚³çœŸ"] = faxes[0]
        if not data.get("çµ±ç·¨") and tax_ids: data["çµ±ç·¨"] = tax_ids[0]
        
        return data
    except:
        # 4. è¬ä¸€ AI å®Œå…¨å´©æ½°ï¼Œå›å‚³ Regex æŠ“åˆ°çš„åŸºæœ¬è³‡æ–™
        return {
            "å…¬å¸åç¨±": company_name_hint,
            "é›»è©±": phones[0] if phones else "",
            "Email": emails[0] if emails else "",
            "å‚³çœŸ": faxes[0] if faxes else "",
            "çµ±ç·¨": tax_ids[0] if tax_ids else "",
            "å‚™è¨»": "AIå¤±æ•—ï¼Œåƒ…æ­£å‰‡æŠ“å–"
        }

def generate_keywords(base_keyword, amount, model):
    """ é—œéµå­—è£‚è®Šç­–ç•¥ """
    num_strategies = max(3, int(amount / 15)) # ä¼°è¨ˆæ¯å€‹é—œéµå­—èƒ½æŠ“ 15 ç­†ä¸é‡è¤‡çš„
    prompt = f"""
    è«‹ç”Ÿæˆ {num_strategies} çµ„æœå°‹é—œéµå­—ï¼Œç›®çš„æ˜¯æœé›†ã€Œ{base_keyword}ã€ç›¸é—œçš„å°ç£å…¬å¸åå–®ã€‚
    è«‹åŒ…å«ï¼šåœ°å€è®Šé«” (å¦‚ {base_keyword} å°ä¸­)ã€æ‡‰ç”¨è®Šé«” (å¦‚ å·¥æ¥­{base_keyword})ã€é•·å°¾è©ã€‚
    åªå›å‚³ JSON Array stringï¼Œä¾‹å¦‚ï¼š["é—œéµå­—1", "é—œéµå­—2", ...]
    """
    try:
        res = model.generate_content(prompt)
        txt = res.text.strip()
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        return json.loads(txt)
    except:
        # å‚™ç”¨ç­–ç•¥
        return [f"{base_keyword} {city}" for city in ["å°åŒ—", "æ¡ƒåœ’", "æ–°ç«¹", "å°ä¸­", "å°å—", "é«˜é›„", "å» å•†", "å·¥ç¨‹", "è¨­å‚™"]]

# --- 4. ä¸»åŸ·è¡Œé‚è¼¯ ---
st.subheader("ğŸ•µï¸â€â™‚ï¸ å•Ÿå‹•æ§åˆ¶å°")
keyword = st.text_input("è¼¸å…¥æ ¸å¿ƒé—œéµå­—", value="å»¢æ°´å›æ”¶ç³»çµ±")

if st.button("ğŸš€ å•Ÿå‹•é‡ç”¢å¼•æ“"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹å¡«å¯« API Key")
        st.stop()
        
    # åˆå§‹åŒ–
    genai.configure(api_key=gemini_api_key)
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        model.generate_content("test")
    except:
        model = genai.GenerativeModel('gemini-pro')
        
    tavily = TavilyClient(api_key=tavily_api_key)
    
    # ç‹€æ…‹é¡¯ç¤º
    status_box = st.status("ğŸ§  AI æˆ°ç•¥è¦åŠƒä¸­...", expanded=True)
    
    # === éšæ®µ 1. é—œéµå­—è£‚è®Š ===
    strategies = generate_keywords(keyword, target_amount, model)
    status_box.write(f"âœ… ç­–ç•¥ç”Ÿæˆï¼šå°‡ä½¿ç”¨ {len(strategies)} çµ„é—œéµå­—é€²è¡Œåœ°æ¯¯å¼æœç´¢ã€‚")
    
    # === éšæ®µ 2. å»ºç«‹ç¶²å€æ±  (URL Pool) ===
    unique_data = {} # ç”¨ä¾†å­˜ {url: {title, raw_content}}
    progress_bar = st.progress(0)
    
    status_box.write("ğŸ•¸ï¸ æ­£åœ¨æ’’ç¶²æ•æ’ˆç¶²å€ (å«åº«å­˜é é¢å‚™ä»½)...")
    
    for idx, q in enumerate(strategies):
        if len(unique_data) >= target_amount: break
        
        try:
            # é—œéµä¿®æ­£ï¼šinclude_raw_content=True æ˜¯è³‡æ–™åº«å­˜çš„æ ¸å¿ƒ
            response = tavily.search(query=q, max_results=15, include_raw_content=True)
            
            for res in response.get('results', []):
                url = res.get('url')
                if url and url not in unique_data:
                    if not url.endswith('.pdf'): # æ’é™¤ PDF
                        unique_data[url] = {
                            "title": res.get('title', ''),
                            # å„ªå…ˆä½¿ç”¨ raw_contentï¼Œè‹¥ç„¡å‰‡ç”¨ content
                            "raw_content": res.get('raw_content') or res.get('content', '') 
                        }
        except Exception as e:
            if debug_mode: st.warning(f"æœå°‹ {q} æ™‚ç•¥é: {e}")
            pass
            
        progress_bar.progress(min(len(unique_data) / target_amount, 1.0))
        status_box.write(f"ğŸ” ç›®å‰åº«å­˜ï¼š{len(unique_data)} ç­† (æ­£åœ¨æœå°‹: {q})")
        time.sleep(1) # é¿å…éå¿«

    # === éšæ®µ 3. æ·±åº¦æŒ–æ˜ ===
    status_box.write(f"ğŸ­ ç¶²å€æœé›†å®Œç•¢ (å…±{len(unique_data)}ç­†)ï¼Œé–‹å§‹é€²è¡Œæ·±åº¦åŠ å·¥èˆ‡è£œå®Œ...")
    
    final_results = []
    process_bar = st.progress(0)
    table_preview = st.empty()
    
    target_list = list(unique_data.items())[:target_amount]
    
    for i, (url, info) in enumerate(target_list):
        title = info['title']
        raw_backup = info['raw_content']
        
        status_box.write(f"ğŸ”¨ ({i+1}/{len(target_list)}) åŠ å·¥ä¸­ï¼š{title}")
        
        try:
            # A. æŠ“å–å…§å®¹ (å„ªå…ˆ Jina -> å¤±æ•—ç”¨åº«å­˜ raw_backup)
            content, source = fetch_content_robust(url, fallback_content=raw_backup)
            
            # B. AI æå–
            data = extract_contact_info(content, url, model, company_name_hint=title)
            data["è³‡æ–™ä¾†æº"] = source
            
            # C. è£œåˆ€æ©Ÿåˆ¶ (Hunter Mode)
            missing = []
            if not data.get("Email") or str(data.get("Email")).lower() in ["none", ""]: missing.append("Email")
            if not data.get("é›»è©±") or str(data.get("é›»è©±")).lower() in ["none", ""]: missing.append("é›»è©±")
            
            if enable_hunter and missing:
                if debug_mode: status_box.write(f"ğŸ”« {title} è³‡æ–™ä¸å…¨ï¼Œç™¼å‹•è£œåˆ€...")
                hunter_data = hunter_search(title, tavily)
                
                # å¾è£œåˆ€è³‡æ–™ä¸­å†æ¬¡æå–
                h_emails, h_phones, h_faxes, h_tax = regex_heavy_duty(hunter_data)
                
                if "Email" in missing and h_emails: data["Email"] = h_emails[0]
                if "é›»è©±" in missing and h_phones: data["é›»è©±"] = h_phones[0]
                if not data.get("å‚³çœŸ") and h_faxes: data["å‚³çœŸ"] = h_faxes[0]
                
                data["å‚™è¨»"] = "ç¶“äºŒæ¬¡è£œå®Œ"
            else:
                 if not data.get("å‚™è¨»"): data["å‚™è¨»"] = "ä¸€èˆ¬"
            
            final_results.append(data)
            
            # é è¦½æ›´æ–°
            if i % 3 == 0:
                df_show = pd.DataFrame(final_results)
                cols = ["å…¬å¸åç¨±", "é›»è©±", "Email", "å‚³çœŸ", "ç¶²å€", "å‚™è¨»"]
                for c in cols: 
                    if c not in df_show.columns: df_show[c] = ""
                table_preview.dataframe(df_show[cols].tail(5))
                
        except Exception as e:
            if debug_mode: st.warning(f"Error on {title}: {e}")
            
        process_bar.progress((i+1)/len(target_list))
        time.sleep(0.5)

    # === éšæ®µ 4. è¼¸å‡º ===
    status_box.update(label="ğŸ‰ ä»»å‹™å®Œæˆï¼", state="complete", expanded=False)
    
    if final_results:
        df_final = pd.DataFrame(final_results)
        
        # æ¬„ä½æ•´ç†
        target_cols = ["å…¬å¸åç¨±", "é›»è©±", "Email", "å‚³çœŸ", "çµ±ç·¨", "ç¶²å€", "å‚™è¨»", "è³‡æ–™ä¾†æº"]
        for c in target_cols:
            if c not in df_final.columns: df_final[c] = ""
        df_final = df_final[target_cols]
        
        # å¼·åˆ¶è½‰å­—ä¸²ï¼Œé¿å… CSV é›»è©±æ‰ 0
        df_final = df_final.astype(str)
        
        st.success(f"å…±ç”¢å‡º {len(df_final)} ç­†æœ‰æ•ˆåå–®")
        st.dataframe(df_final)
        
        # CSV ä¸‹è¼‰ (Excel é–‹å•Ÿä¸äº‚ç¢¼çš„é—œéµï¼šutf-8-sig)
        csv = df_final.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel æ ¼å¼ (CSV)",
            data=csv,
            file_name="leads_production.csv",
            mime="text/csv"
        )