import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urljoin, urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (åœ°æ¯¯å¼æœç´¢ç‰ˆ)", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ å…¨è‡ªå‹•å®¢æˆ¶åå–®æœé›†å™¨ (å…¨ä¾†æºæœåˆ®+æ™ºæ…§åˆ†é¡)")
st.markdown("""
### ğŸš€ é€™æ¬¡çœŸçš„æŒ–åœ°ä¸‰å°ºäº†ï¼š
1. **å‚³çœŸå¢å¼·**ï¼šæ”¯æ´ `F:` `F.` `FAX` `å‚³çœŸ` `Facsimile` ç­‰ 10 ç¨®å¯«æ³•ã€‚
2. **é è¦½æ•‘æ´**ï¼šå¦‚æœç¶²é è£¡æ‰¾ä¸åˆ°ï¼Œç¨‹å¼æœƒå›é ­å»ç¿» **ã€Œæœå°‹å¼•æ“çš„æ‘˜è¦ã€**ï¼Œå¾€å¾€ Email å°±è—åœ¨é‚£è£¡ï¼
3. **æ™ºæ…§åˆ†é¡**ï¼šç¶­æŒé›»è©±èˆ‡çµ±ç·¨è‡ªå‹•åˆ†é›¢çš„åŠŸèƒ½ã€‚
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    if "GEMINI_API_KEY" in st.secrets:
        gemini_api_key = st.secrets["GEMINI_API_KEY"]
        st.success("âœ… å·²è®€å– Gemini Key")
    else:
        gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")

    if "TAVILY_API_KEY" in st.secrets:
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
        st.success("âœ… å·²è®€å– Tavily Key")
    else:
        tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")

    num_results = st.slider("æœå°‹æ•¸é‡", 3, 20, 5) 
    debug_mode = st.toggle("é¡¯ç¤ºå¾Œå°è™•ç†éç¨‹", value=True)

# --- 3. æ ¸å¿ƒå·¥å…· ---

def get_root_url(url):
    """ å¼·åˆ¶è½‰å›é¦–é  """
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def find_contact_link(markdown_text, root_url):
    """ å°‹æ‰¾è¯çµ¡æˆ‘å€‘é€£çµ """
    links = re.findall(r'\[(.*?)\]\((.*?)\)', markdown_text)
    keywords = ["è¯çµ¡", "contact", "about", "é—œæ–¼", "support", "inquiry", "è©¢åƒ¹"]
    
    for text, link in links:
        for kw in keywords:
            if kw in text.lower():
                full_link = urljoin(root_url, link)
                return full_link, text
    return None, None

def fetch_content_smart(url, fallback_content=""):
    """ æ™ºæ…§æŠ“å–æµç¨‹ """
    if fallback_content is None: fallback_content = ""
    
    combined_content = ""
    source_log = []

    root_url = get_root_url(url)
    jina_url = f"https://r.jina.ai/{root_url}"
    
    try:
        resp = requests.get(jina_url, timeout=10)
        if resp.status_code == 200 and len(resp.text) > 200:
            homepage_text = resp.text
            combined_content += f"\n=== é¦–é  ===\n{homepage_text[:20000]}"
            source_log.append("é¦–é ")
            
            # å¦‚æœé¦–é çœ‹èµ·ä¾†æ²’ä»€éº¼è¯çµ¡è³‡è¨Šï¼Œå˜—è©¦æ‰¾é€£çµ
            if "@" not in homepage_text and "Fax" not in homepage_text:
                contact_link, link_text = find_contact_link(homepage_text, root_url)
                if contact_link:
                    source_log.append(f"å…§é ({link_text})")
                    jina_contact_url = f"https://r.jina.ai/{contact_link}"
                    resp_inner = requests.get(jina_contact_url, timeout=10)
                    if resp_inner.status_code == 200:
                        combined_content += f"\n=== å…§é  ===\n{resp_inner.text[:20000]}"
        else:
            if len(fallback_content) > 50:
                combined_content = fallback_content
                source_log.append("åº«å­˜")
                
    except:
        if len(fallback_content) > 50:
            combined_content = fallback_content
            source_log.append("åº«å­˜(æ•‘æ´)")

    return combined_content, " + ".join(source_log)

def regex_heavy_duty(text):
    """ å¼·åŠ›æƒæ + æ™ºæ…§åˆ†é¡ + å‚³çœŸå¢å¼· """
    if not text: return [], [], [], []
    
    text_clean = " ".join(text.split())
    
    # 1. æŠ“ Email
    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
    mailto_emails = re.findall(r'mailto:([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', text)
    all_emails = list(set(emails + mailto_emails))

    # 2. æŠ“ å‚³çœŸ (Fax) - å¢å¼·ç‰ˆè¦å‰‡
    # æ”¯æ´: Fax: 02-xxx, F: 02-xxx, T/F: 02-xxx, å‚³çœŸ: 02-xxx
    fax_patterns = [
        r'(?:Fax|FAX|å‚³çœŸ|Facsimile)[\s:ï¼š\.]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})',
        r'(?:F\.|F:)[\s]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})', # é‡å° F. 02-xxxx
    ]
    
    faxes = []
    for pattern in fax_patterns:
        found = re.findall(pattern, text)
        faxes.extend(found)
    faxes = list(set(faxes))
    
    # 3. æŠ“ æ‰€æœ‰æ•¸å­—ä¸² (ç–‘ä¼¼é›»è©±æˆ–çµ±ç·¨)
    raw_numbers = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
    
    phones = []
    tax_ids = [] # çµ±ç·¨
    
    for num in list(set(raw_numbers)):
        clean_num = re.sub(r'\D', '', num) # åªç•™æ•¸å­—
        
        # éæ¿¾æ‰å·²ç¶“è¢«ç•¶æˆå‚³çœŸçš„è™Ÿç¢¼
        is_fax = False
        for f in faxes:
            if clean_num in re.sub(r'\D', '', f):
                is_fax = True
                break
        if is_fax: continue

        # åˆ†é¡é‚è¼¯
        if len(clean_num) >= 8:
            if clean_num.startswith('0'): 
                phones.append(num)
            elif len(clean_num) == 8:
                tax_ids.append(clean_num)
            else:
                phones.append(num)

    return all_emails, phones, faxes, tax_ids

# --- 4. AI åˆ†æå‡½æ•¸ ---

def extract_contact_info(content, url, model, snippet_content=""):
    # é€™è£¡å¾ˆé—œéµï¼šæˆ‘å€‘æŠŠã€Œæœå°‹å¼•æ“çš„æ‘˜è¦ (Snippet)ã€ä¹ŸåŠ é€²å»æƒæï¼
    # å› ç‚ºæœ‰æ™‚å€™ Email å°±ç›´æ¥å¯«åœ¨ Google æœå°‹çµæœä¸Šï¼Œä½†ç¶²é è£¡å»æ²’æœ‰
    full_text_scan = content + "\n" + snippet_content
    
    emails, phones, faxes, tax_ids = regex_heavy_duty(full_text_scan)
    
    try:
        backup_info = f"Email: {emails[:3]}, é›»è©±: {phones[:3]}, å‚³çœŸ: {faxes[:2]}"
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–æ©Ÿå™¨äººã€‚è«‹åˆ†æç¶²é å…§å®¹æ‰¾å‡ºè¯çµ¡æ–¹å¼ã€‚
        
        ç¶²å€ï¼š{url}
        åƒè€ƒæ•¸æ“šï¼š{backup_info}

        ç¶²é å…§å®¹ï¼š
        {content[:40000]} 
        
        è«‹å›å‚³ JSONï¼š
        {{
            "å…¬å¸åç¨±": "...", 
            "é›»è©±": "...", 
            "Email": "...",
            "å‚³çœŸ": "...",
            "ç¶²å€": "{url}"
        }}
        """
        response = model.generate_content(prompt)
        txt = response.text.strip()
        
        if "```json" in txt:
            txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt:
            txt = txt.split("```")[0]
            
        data = json.loads(txt)

        # --- å¼·åŠ›å›å¡«æ©Ÿåˆ¶ ---
        if (not data.get("Email") or str(data.get("Email")).lower() in ["none", "", "null"]) and emails:
            data["Email"] = ", ".join(emails[:2])
            
        if (not data.get("é›»è©±") or str(data.get("é›»è©±")).lower() in ["none", "", "null"]) and phones:
            data["é›»è©±"] = ", ".join(phones[:2])
            
        if (not data.get("å‚³çœŸ") or str(data.get("å‚³çœŸ")).lower() in ["none", "", "null"]) and faxes:
            data["å‚³çœŸ"] = faxes[0]

        if tax_ids:
            data["çµ±ç·¨"] = ", ".join(tax_ids[:1])
        else:
            data["çµ±ç·¨"] = ""

        return data

    except:
        return {
            "å…¬å¸åç¨±": "ERROR", 
            "é›»è©±": ", ".join(phones[:2]), 
            "Email": ", ".join(emails[:2]), 
            "å‚³çœŸ": faxes[0] if faxes else "",
            "çµ±ç·¨": ", ".join(tax_ids[:1]),
            "ç¶²å€": url
        }

# --- 5. ä¸»ç¨‹å¼ ---
keyword = st.text_input("ğŸ” è«‹è¼¸å…¥æœå°‹é—œéµå­—", value="å»¢æ°´å›æ”¶ç³»çµ± å…¬å¸")

if st.button("é–‹å§‹æœå°‹èˆ‡åˆ†æ"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹è¼¸å…¥ API Key")
    else:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        tavily = TavilyClient(api_key=tavily_api_key)
        
        status_box = st.status("ğŸš€ å•Ÿå‹•åœ°æ¯¯å¼æœç´¢...", expanded=True)
        results_list = []
        
        try:
            status_box.write(f"æ­£åœ¨æœå°‹ï¼š{keyword}...")
            response = tavily.search(query=keyword, max_results=num_results, include_raw_content=True)
            search_results = response.get('results', [])
            
            if not search_results:
                status_box.error("æ‰¾ä¸åˆ°ç¶²å€")
            else:
                progress_bar = st.progress(0)
                
                for i, item in enumerate(search_results):
                    try:
                        url = item.get('url', 'ç„¡ç¶²å€')
                        title = item.get('title', 'ç„¡æ¨™é¡Œ')
                        tavily_raw = item.get('raw_content') or "" # é€™æ˜¯ç¶²é å…§æ–‡åº«å­˜
                        tavily_snippet = item.get('content') or "" # é€™æ˜¯æœå°‹å¼•æ“ä¸Šçš„æ‘˜è¦
                        
                        status_box.write(f"({i+1}/{len(search_results)}) åˆ†æï¼š{title}")
                        
                        content, source_log = fetch_content_smart(url, fallback_content=tavily_raw)
                        
                        if debug_mode:
                            with st.expander(f"ğŸ” è¿½è¹¤è·¯å¾‘: {source_log}"):
                                # é€™è£¡æˆ‘å€‘æŠŠæ‘˜è¦ä¹ŸåŠ é€²å»æƒæ
                                emails, phones, faxes, taxes = regex_heavy_duty(content + "\n" + tavily_snippet)
                                st.write(f"æƒæçµæœ -> Email: {len(emails)}, å‚³çœŸ: {len(faxes)}, çµ±ç·¨: {len(taxes)}")
                        
                        # åªè¦æœ‰ä»»ä½•å…§å®¹ï¼Œæˆ‘å€‘å°±è©¦è‘—åˆ†æ
                        if len(content) > 50 or len(tavily_snippet) > 20:
                            # æ³¨æ„ï¼šæˆ‘å€‘æŠŠ tavily_snippet ä¹Ÿå‚³é€²å»äº†
                            data = extract_contact_info(content, url, model, snippet_content=tavily_snippet)
                            
                            name = str(data.get("å…¬å¸åç¨±", ""))
                            if name in ["ERROR", "None"] or "å¤±æ•—" in name:
                                data["å…¬å¸åç¨±"] = title
                            
                            results_list.append(data)
                        else:
                            pass
                            
                    except:
                        pass
                        
                    progress_bar.progress((i + 1) / len(search_results))
                    time.sleep(1)

                status_box.update(label="ğŸ‰ æœé›†å®Œæˆï¼", state="complete", expanded=False)
                
                if results_list:
                    df = pd.DataFrame(results_list)
                    cols = ["å…¬å¸åç¨±", "çµ±ç·¨", "é›»è©±", "Email", "å‚³çœŸ", "ç¶²å€"]
                    
                    for c in cols:
                        if c not in df.columns: df[c] = ""
                    df = df[cols]

                    st.dataframe(df)
                    
                    excel_file = "leads_complete.xlsx"
                    df.to_excel(excel_file, index=False)
                    with open(excel_file, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel åå–®", f, file_name=f"{keyword}_åœ°æ¯¯å¼åå–®.xlsx")

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")