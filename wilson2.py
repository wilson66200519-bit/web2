import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urljoin, urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (å°ç£ç²¾æº–ç‰ˆ)", layout="wide")
st.title("ğŸ‡¹ğŸ‡¼ å…¨è‡ªå‹•å®¢æˆ¶åå–®å·¥å»  (å°ç£ç²¾æº–ç‰ˆ)")
st.markdown("""
### ğŸ›¡ï¸ æœ¬æ¬¡ä¿®æ­£é‡é»ï¼š
1. **åš´æ ¼å€åˆ†çµ±ç·¨èˆ‡é›»è©±**ï¼š8 ç¢¼ä¸”é 0 é–‹é ­çš„æ•¸å­—ï¼Œè‡ªå‹•æ­¸é¡ç‚ºçµ±ç·¨ï¼Œä¸å†èª¤åˆ¤ç‚ºé›»è©±ã€‚
2. **é–å®šå°ç£å» å•†**ï¼šæœå°‹æ™‚å¼·åˆ¶åŠ ä¸Š "å°ç£"ï¼Œä¸¦è‡ªå‹•éæ¿¾ `.cn` (ä¸­åœ‹) ç¶²åŸŸã€‚
3. **åç¨±AIæ¸…æ´—**ï¼šåˆ©ç”¨ AI åˆ¤æ–·ç¶²é æ¨™é¡Œï¼Œé‚„åŸå‡ºæœ€ä¹¾æ·¨çš„å…¬å¸å…¨åï¼ˆå»é™¤ "é¦–é "ã€"å°ˆæ¥­è£½é€ " ç­‰è´…å­—ï¼‰ã€‚
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ API è¨­å®š")
    try:
        gemini_api_key = st.secrets["GEMINI_API_KEY"]
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
        st.success("âœ… API Key å·²å¾ Secrets è¼‰å…¥")
    except:
        gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")
        tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")
    
    st.divider()
    target_amount = st.slider("ç›®æ¨™è³‡æ–™ç­†æ•¸", 10, 500, 30, step=10)
    enable_hunter = st.toggle("é–‹å•Ÿã€Œè£œåˆ€è¿½æ®ºã€", value=True)
    debug_mode = st.toggle("é¡¯ç¤ºé™¤éŒ¯è¨Šæ¯", value=False)

# --- 3. æ ¸å¿ƒå·¥å…·å‡½æ•¸ ---

def get_root_url(url):
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def fetch_content_robust(url, fallback_content=""):
    """ å¼·éŸŒçˆ¬å–æµç¨‹ """
    # ğŸš« éæ¿¾ä¸­åœ‹ç¶²åŸŸ
    if ".cn" in url or "china" in url.lower():
        return "", "éå°ç£ç¶²åŸŸ(éæ¿¾)"

    combined_content = ""
    source_log = []
    root_url = get_root_url(url)
    
    jina_url = f"https://r.jina.ai/{root_url}"
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(jina_url, headers=headers, timeout=8)
        
        # ç°¡å–®æª¢æŸ¥æ˜¯å¦ç‚ºç°¡é«”ä¸­æ–‡ç¶²ç«™ (å‡ºç¾å¤§é‡ç°¡é«”ç‰¹å¾µå­—)
        if "è”ç³»æˆ‘ä»¬" in resp.text or "æœ‰é™å…¬å¸" in resp.text: 
            # é€™è£¡åªæ˜¯ä¸€å€‹ç°¡å–®åˆ¤æ–·ï¼Œæœªå¿…æº–ç¢ºï¼Œä½†èƒ½æ“‹æ‰ä¸€éƒ¨åˆ†
            pass 

        if resp.status_code == 200 and len(resp.text) > 100:
            combined_content += f"\n=== Jinaå³æ™‚çˆ¬å– ===\n{resp.text[:15000]}"
            source_log.append("å³æ™‚çˆ¬èŸ²")
        else:
            raise Exception("Jina fail")
            
    except Exception as e:
        if fallback_content and len(fallback_content) > 50:
            combined_content += f"\n=== æœå°‹å¼•æ“åº«å­˜ ===\n{fallback_content[:15000]}"
            source_log.append("åº«å­˜æ•‘æ´")
        else:
            source_log.append("æŠ“å–å¤±æ•—")

    return combined_content, " + ".join(source_log)

def regex_heavy_duty(text):
    """ 
    ä¿®æ­£å¾Œçš„å¼·åŠ›æƒæï¼š
    1. åš´æ ¼å€åˆ† 8 ç¢¼çµ±ç·¨ vs é›»è©±
    2. éæ¿¾ä¸­åœ‹æ‰‹æ©Ÿè™Ÿ (11ç¢¼, 1é–‹é ­)
    """
    if not text: return [], [], [], []
    text_clean = " ".join(text.split())
    
    # Email
    emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
    all_emails = list(set(emails))

    # å‚³çœŸ (Fax)
    fax_patterns = [r'(?:Fax|FAX|å‚³çœŸ|F\.|F:)[\s:ï¼š\.]*(\(?0\d{1,2}\)?[\s\-]?[0-9-]{6,15})']
    faxes = []
    for pattern in fax_patterns:
        faxes.extend(re.findall(pattern, text))
    faxes = list(set(faxes))
    
    # é›»è©±èˆ‡çµ±ç·¨é‚è¼¯é‡æ§‹
    raw_numbers = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
    phones = []
    tax_ids = []
    
    for num in list(set(raw_numbers)):
        clean_num = re.sub(r'\D', '', num)
        
        # æ’é™¤å‚³çœŸ
        is_fax = False
        for f in faxes:
            if clean_num in re.sub(r'\D', '', f): is_fax = True; break
        if is_fax: continue

        # ğŸš« æ’é™¤ä¸­åœ‹æ‰‹æ©Ÿè™Ÿ (1é–‹é ­, 11ç¢¼)
        if len(clean_num) == 11 and clean_num.startswith('1'):
            continue

        # âœ… çµ±ç·¨åˆ¤æ–·ï¼š8ç¢¼ï¼Œä¸”é€šå¸¸ä¸ä»¥ 0 é–‹é ­ (å°ç£æ‰‹æ©Ÿæ˜¯ 09 é–‹é ­å…± 10 ç¢¼ï¼Œå¸‚è©±å«å€ç¢¼ 9-10 ç¢¼)
        if len(clean_num) == 8 and not clean_num.startswith('0'):
            tax_ids.append(clean_num)
        # âœ… é›»è©±åˆ¤æ–·ï¼š9ç¢¼ä»¥ä¸Šï¼Œæˆ–æ˜¯ 8 ç¢¼ä½†ä»¥ 0 é–‹é ­ (æ¥µå°‘è¦‹ï¼Œå¯èƒ½æ˜¯æœªåŠ å€ç¢¼çš„å¸‚è©±ï¼Œå…ˆæ­¸é¡ç‚ºé›»è©±)
        elif len(clean_num) >= 8:
            phones.append(num)

    return all_emails, phones, faxes, tax_ids

def hunter_search(company_name, tavily_client):
    """ è£œåˆ€æœå°‹ï¼šåŠ ä¸Š 'å°ç£' é—œéµå­— """
    if not company_name or len(company_name) < 2: return ""
    # å¼·åˆ¶åŠ ä¸Š "å°ç£" é¿å…æœåˆ°å¤§é™¸åŒåå…¬å¸
    query = f"{company_name} å°ç£ é›»è©± email è¯çµ¡æ–¹å¼"
    try:
        resp = tavily_client.search(query=query, max_results=3, search_depth="advanced")
        snippets = ""
        for res in resp.get('results', []):
            snippets += res.get('content', '') + "\n"
        return snippets
    except:
        return ""

def extract_contact_info(content, url, model, company_name_hint=""):
    """ Gemini AI èƒå– (åŠ å…¥åç¨±æ¸…æ´—æŒ‡ä»¤) """
    if "éå°ç£ç¶²åŸŸ" in content: # å¿«é€Ÿå¤±æ•—
        return {"å…¬å¸åç¨±": company_name_hint, "å‚™è¨»": "æ’é™¤(éå°ç£ç¶²åŸŸ)"}

    emails, phones, faxes, tax_ids = regex_heavy_duty(content)
    backup_info = f"é æƒæ -> Email:{emails[:1]}, é›»è©±:{phones[:1]}, çµ±ç·¨:{tax_ids[:1]}"
    
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–å°ˆå®¶ã€‚è«‹è™•ç†ä»¥ä¸‹å°ç£å…¬å¸çš„è³‡æ–™ã€‚
    
    ç¶²å€ï¼š{url}
    åŸå§‹æ¨™é¡Œï¼š{company_name_hint}
    åƒè€ƒæ•¸æ“šï¼š{backup_info}
    ç¶²é å…§å®¹ï¼š
    {content[:20000]} 
    
    ä»»å‹™ 1: æ¸…æ´—å…¬å¸åç¨±ã€‚è«‹å¾åŸå§‹æ¨™é¡Œæˆ–å…§æ–‡ä¸­æ‰¾å‡ºã€Œæ­£å¼å…¨åã€ã€‚
           (ä¾‹å¦‚: "é¦–é  - å»ºè¶Šç§‘æŠ€å»¢æ°´è™•ç†" -> "å»ºè¶Šç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸")
           (ä¾‹å¦‚: "Good Water Co." -> "Good Water Co.")
           å¦‚æœä¸ç¢ºå®šï¼Œå°±ä¿ç•™æœ€åƒå…¬å¸åçš„éƒ¨åˆ†ã€‚
           
    ä»»å‹™ 2: æå–è¯çµ¡è³‡è¨Šã€‚
    
    è«‹å›å‚³ç´” JSON:
    {{
        "å…¬å¸åç¨±": "...", 
        "é›»è©±": "...", 
        "Email": "...",
        "å‚³çœŸ": "...",
        "çµ±ç·¨": "...",
        "å‚™è¨»": "..."
    }}
    è‹¥æ‰¾ä¸åˆ°ï¼Œå„ªå…ˆä½¿ç”¨åƒè€ƒæ•¸æ“šã€‚
    """
    
    try:
        response = model.generate_content(prompt)
        txt = response.text.strip()
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt: txt = txt.split("```")[0]
        data = json.loads(txt)
        
        # å¼·åŠ›å›å¡«
        if not data.get("Email") and emails: data["Email"] = emails[0]
        if not data.get("é›»è©±") and phones: data["é›»è©±"] = phones[0]
        if not data.get("å‚³çœŸ") and faxes: data["å‚³çœŸ"] = faxes[0]
        if not data.get("çµ±ç·¨") and tax_ids: data["çµ±ç·¨"] = tax_ids[0]
        
        return data
    except:
        return {
            "å…¬å¸åç¨±": company_name_hint,
            "é›»è©±": phones[0] if phones else "",
            "Email": emails[0] if emails else "",
            "å‚³çœŸ": faxes[0] if faxes else "",
            "çµ±ç·¨": tax_ids[0] if tax_ids else "",
            "å‚™è¨»": "AIè§£æå¤±æ•—"
        }

def generate_keywords(base_keyword, amount, model):
    """ ç”Ÿæˆç­–ç•¥ï¼šå¼·åˆ¶åŠ ä¸Š 'å°ç£' """
    num_strategies = max(3, int(amount / 15))
    prompt = f"""
    è«‹ç”Ÿæˆ {num_strategies} çµ„æœå°‹é—œéµå­—ï¼Œç›®çš„æ˜¯æœé›†ã€Œå°ç£ã€çš„ã€Œ{base_keyword}ã€å» å•†ã€‚
    è«‹ç¢ºä¿é—œéµå­—éƒ½åŒ…å« "å°ç£" æˆ–å°ç£åœ°å (å°åŒ—, å°ä¸­, é«˜é›„)ã€‚
    åªå›å‚³ JSON Array string: ["é—œéµå­—1", "é—œéµå­—2", ...]
    """
    try:
        res = model.generate_content(prompt)
        txt = res.text.strip()
        if "```json" in txt: txt = txt.split("```json")[1].split("```")[0]
        return json.loads(txt)
    except:
        return [f"å°ç£ {base_keyword}", f"å°åŒ— {base_keyword}", f"å°ä¸­ {base_keyword}", f"é«˜é›„ {base_keyword}"]

# --- 4. ä¸»åŸ·è¡Œé‚è¼¯ ---
st.subheader("ğŸ•µï¸â€â™‚ï¸ å•Ÿå‹•æ§åˆ¶å°")
keyword = st.text_input("è¼¸å…¥æ ¸å¿ƒé—œéµå­— (ç³»çµ±æœƒè‡ªå‹•é™å®šå°ç£ç¯„åœ)", value="å»¢æ°´å›æ”¶ç³»çµ±")

if st.button("ğŸš€ å•Ÿå‹•å°ç£ç²¾æº–ç‰ˆå¼•æ“"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹å¡«å¯« API Key")
        st.stop()
        
    genai.configure(api_key=gemini_api_key)
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        model.generate_content("test")
    except:
        model = genai.GenerativeModel('gemini-pro')
        
    tavily = TavilyClient(api_key=tavily_api_key)
    status_box = st.status("ğŸ§  è¦åŠƒå°ç£é™å®šæœå°‹ç­–ç•¥...", expanded=True)
    
    # 1. ç­–ç•¥ç”Ÿæˆ
    strategies = generate_keywords(keyword, target_amount, model)
    status_box.write(f"âœ… æœå°‹ç­–ç•¥ï¼š{strategies}")
    
    # 2. æœé›†ç¶²å€ (éæ¿¾ .cn)
    unique_data = {} 
    progress_bar = st.progress(0)
    status_box.write("ğŸ•¸ï¸ æ­£åœ¨éæ¿¾ä¸¦æœé›†ç¶²å€...")
    
    for idx, q in enumerate(strategies):
        if len(unique_data) >= target_amount: break
        try:
            response = tavily.search(query=q, max_results=15, include_raw_content=True)
            for res in response.get('results', []):
                url = res.get('url')
                # ğŸš« ç¶²åŸŸå±¤ç´šéæ¿¾
                if url and ".cn" not in url and "alibaba" not in url and not url.endswith('.pdf'):
                    if url not in unique_data:
                        unique_data[url] = {
                            "title": res.get('title', ''),
                            "raw_content": res.get('raw_content') or res.get('content', '') 
                        }
        except: pass
        progress_bar.progress(min(len(unique_data) / target_amount, 1.0))
        time.sleep(1)

    # 3. æ·±åº¦æŒ–æ˜
    status_box.write(f"ğŸ­ é–‹å§‹è™•ç† {len(unique_data)} ç­†å°ç£å» å•†è³‡æ–™...")
    final_results = []
    process_bar = st.progress(0)
    table_preview = st.empty()
    
    target_list = list(unique_data.items())[:target_amount]
    
    for i, (url, info) in enumerate(target_list):
        title = info['title']
        raw_backup = info['raw_content']
        
        try:
            content, source = fetch_content_robust(url, fallback_content=raw_backup)
            
            # è‹¥ç¬¬ä¸€æ­¥å°±ç™¼ç¾æ˜¯éå°ç£ç¶²åŸŸï¼Œè·³é
            if "éå°ç£ç¶²åŸŸ" in source:
                continue

            data = extract_contact_info(content, url, model, company_name_hint=title)
            data["è³‡æ–™ä¾†æº"] = source
            
            # è£œåˆ€æª¢æŸ¥
            missing = []
            if not data.get("Email") or str(data.get("Email")).lower() in ["none", ""]: missing.append("Email")
            if not data.get("é›»è©±") or str(data.get("é›»è©±")).lower() in ["none", ""]: missing.append("é›»è©±")
            
            if enable_hunter and missing:
                if debug_mode: status_box.write(f"ğŸ”« {data['å…¬å¸åç¨±']} è³‡æ–™ä¸å…¨ï¼Œè£œåˆ€ä¸­...")
                hunter_data = hunter_search(data['å…¬å¸åç¨±'], tavily)
                h_emails, h_phones, h_faxes, h_tax = regex_heavy_duty(hunter_data)
                
                if "Email" in missing and h_emails: data["Email"] = h_emails[0]
                if "é›»è©±" in missing and h_phones: data["é›»è©±"] = h_phones[0]
                if not data.get("çµ±ç·¨") and h_tax: data["çµ±ç·¨"] = h_tax[0] # è£œåˆ€ä¹Ÿè¦è£œçµ±ç·¨
                
                data["å‚™è¨»"] = "ç¶“äºŒæ¬¡è£œå®Œ"
            else:
                 if not data.get("å‚™è¨»"): data["å‚™è¨»"] = "ä¸€èˆ¬"
            
            final_results.append(data)
            
            if i % 2 == 0:
                df_show = pd.DataFrame(final_results)
                cols = ["å…¬å¸åç¨±", "çµ±ç·¨", "é›»è©±", "Email", "ç¶²å€"]
                for c in cols: 
                    if c not in df_show.columns: df_show[c] = ""
                table_preview.dataframe(df_show[cols].tail(5))
                
        except Exception as e:
            if debug_mode: st.warning(f"Error: {e}")
            
        process_bar.progress((i+1)/len(target_list))
        time.sleep(0.5)

    status_box.update(label="ğŸ‰ å®Œæˆï¼", state="complete", expanded=False)
    
    if final_results:
        df_final = pd.DataFrame(final_results)
        target_cols = ["å…¬å¸åç¨±", "çµ±ç·¨", "é›»è©±", "Email", "å‚³çœŸ", "ç¶²å€", "å‚™è¨»", "è³‡æ–™ä¾†æº"]
        for c in target_cols:
            if c not in df_final.columns: df_final[c] = ""
        df_final = df_final[target_cols].astype(str)
        
        st.success(f"å…±ç”¢å‡º {len(df_final)} ç­†å°ç£å» å•†åå–®")
        st.dataframe(df_final)
        
        csv = df_final.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰åå–® (CSV)", csv, "taiwan_leads.csv", "text/csv")