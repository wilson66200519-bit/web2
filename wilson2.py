import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (ä¸å€’ç¿ç‰ˆ)", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ å…¨è‡ªå‹•å®¢æˆ¶åå–®æœé›†å™¨ (æ°¸ä¸ç•¶æ©Ÿç‰ˆ)")
st.markdown("""
### ğŸ›¡ï¸ ç©©å®šæ€§æ‰¿è«¾ï¼š
é€™ç‰ˆæœ¬åŠ å…¥äº† **ã€Œè¿´åœˆç¨ç«‹ä¿è­·ã€** æ©Ÿåˆ¶ã€‚
å³ä½¿æŸå€‹ç¶²ç«™å°è‡´éŒ¯èª¤ï¼Œç¨‹å¼æœƒè‡ªå‹•è¨˜éŒ„ä¸¦**è·³éè©²ç­†**ï¼Œç¹¼çºŒåŸ·è¡Œä¸‹ä¸€ç­†ã€‚
**ä¿è­‰ä»»å‹™ä¸€å®šæœƒåŸ·è¡Œåˆ°æœ€å¾Œï¼**
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")
    tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")
    num_results = st.slider("æœå°‹æ•¸é‡", 3, 20, 5) 
    debug_mode = st.toggle("é¡¯ç¤ºé™¤éŒ¯è¨Šæ¯ (Debug)", value=True)

# --- 3. æ ¸å¿ƒå·¥å…· ---

def get_root_url(url):
    """ å¼·åˆ¶è½‰å›é¦–é  (å«é˜²å‘†) """
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def fetch_content_smart(url, fallback_content=""):
    """
    æ™ºæ…§æŠ“å–æµç¨‹ï¼šJina -> Tavilyåº«å­˜
    """
    # [é˜²å‘†] ç¢ºä¿ fallback ä¸æ˜¯ None
    if fallback_content is None:
        fallback_content = ""

    # å˜—è©¦ 1: ç”¨ Jina æŠ“é¦–é 
    try:
        target_url = get_root_url(url)
        jina_url = f"https://r.jina.ai/{target_url}"
        resp = requests.get(jina_url, timeout=10)
        if resp.status_code == 200 and len(resp.text) > 200:
            return resp.text, "Jina (é¦–é )"
    except:
        pass # å¤±æ•—å°±é»˜é»˜ç•¥é
    
    # å˜—è©¦ 2: ç”¨ Tavily åº«å­˜
    if len(fallback_content) > 50:
        return fallback_content, "Tavilyåº«å­˜"
        
    return "", "æŠ“å–å¤±æ•—"

def regex_backup(text):
    """ æš´åŠ›æƒæé›»è©±å’Œ Email """
    if not text: return [], []
    
    try:
        text_clean = " ".join(text.split())
        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
        phones = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
        valid_phones = [p for p in list(set(phones)) if len(re.sub(r'\D', '', p)) >= 8]
        return list(set(emails)), valid_phones
    except:
        return [], []

# --- 4. AI åˆ†æå‡½æ•¸ ---

def extract_contact_info(content, url, model):
    try:
        emails, phones = regex_backup(content)
        backup_info = f"Email: {emails[:3]}, é›»è©±: {phones[:5]}"

        prompt = f"""
        ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–æ©Ÿå™¨äººã€‚è«‹åˆ†æä»¥ä¸‹ç¶²é å…§å®¹ï¼Œæ‰¾å‡ºå…¬å¸è¯çµ¡æ–¹å¼ã€‚
        
        ç¶²å€ï¼š{url}
        åƒè€ƒæ•¸æ“šï¼š{backup_info}

        ç¶²é å…§å®¹æ‘˜è¦ï¼š
        {content[:60000]}
        
        è«‹å›å‚³ JSONï¼š
        {{
            "å…¬å¸åç¨±": "...", 
            "é›»è©±": "...", 
            "Email": "...",
            "ç¶²å€": "{url}"
        }}
        è‹¥æ‰¾ä¸åˆ°ï¼Œè«‹å¡«å…¥åƒè€ƒæ•¸æ“šã€‚
        """
        response = model.generate_content(prompt)
        txt = response.text.strip()
        
        # JSON æ¸…æ´—
        if "```json" in txt:
            txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt:
            txt = txt.split("```")[0]
            
        return json.loads(txt)
    except Exception as e:
        # é€™è£¡ä¹ŸåŠ äº†é˜²è­·ï¼ŒAI å¤±æ•—å°±å›å‚³åŸºæœ¬è³‡æ–™
        return {
            "å…¬å¸åç¨±": "AIè§£æå¤±æ•—", 
            "é›»è©±": "", 
            "Email": "", 
            "ç¶²å€": url,
            "å‚™è¨»": str(e)
        }

# --- 5. ä¸»ç¨‹å¼ ---
keyword = st.text_input("ğŸ” è«‹è¼¸å…¥æœå°‹é—œéµå­—", value="å»¢æ°´å›æ”¶ç³»çµ± å…¬å¸")

if st.button("é–‹å§‹æœå°‹èˆ‡åˆ†æ"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹è¼¸å…¥ API Key")
    else:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        tavily = TavilyClient(api_key=tavily_api_key)
        
        status_box = st.status("ğŸš€ ä»»å‹™å•Ÿå‹•...", expanded=True)
        results_list = []
        
        # [æœ€å¤–å±¤ä¿è­·] æœå°‹éšæ®µ
        try:
            status_box.write(f"æ­£åœ¨æœå°‹ï¼š{keyword}...")
            response = tavily.search(query=keyword, max_results=num_results, include_raw_content=True)
            search_results = response.get('results', [])
            
            if not search_results:
                status_box.error("æ‰¾ä¸åˆ°ç¶²å€")
            else:
                progress_bar = st.progress(0)
                
                # --- [é—œéµæ”¹é€²] è¿´åœˆå…§éƒ¨ä¿è­· ---
                for i, item in enumerate(search_results):
                    try: 
                        # æ¯ä¸€ç­†è³‡æ–™éƒ½ç¨ç«‹è™•ç†ï¼Œä¸€ç­†å¤±æ•—ä¸æœƒå½±éŸ¿ä¸‹ä¸€ç­†
                        url = item.get('url', 'ç„¡ç¶²å€')
                        title = item.get('title', 'ç„¡æ¨™é¡Œ')
                        tavily_raw = item.get('raw_content') or "" # å†æ¬¡ç¢ºä¿ä¸æ˜¯ None
                        
                        status_box.write(f"({i+1}/{len(search_results)}) åˆ†æï¼š{title}")
                        
                        # åŸ·è¡ŒæŠ“å–
                        content, source = fetch_content_smart(url, fallback_content=tavily_raw)
                        
                        if debug_mode:
                            with st.expander(f"ğŸ“ {title} ä¾†æº: {source}"):
                                st.text(content[:100] + "...")
                        
                        if len(content) > 50:
                            data = extract_contact_info(content, url, model)
                            # è£œæ¨™é¡Œ
                            if not data.get("å…¬å¸åç¨±") or "è§£æå¤±æ•—" in str(data.get("å…¬å¸åç¨±")):
                                data["å…¬å¸åç¨±"] = title
                            
                            data["è³‡æ–™ä¾†æº"] = source
                            results_list.append(data)
                        else:
                            results_list.append({"å…¬å¸åç¨±": title, "é›»è©±": "ç„¡å…§å®¹", "ç¶²å€": url, "è³‡æ–™ä¾†æº": "å¤±æ•—"})
                            
                    except Exception as inner_e:
                        # è¬ä¸€é€™ä¸€ç­†çœŸçš„çˆ†ç‚¸äº†ï¼Œå°å‡ºéŒ¯èª¤ï¼Œä½†ç¹¼çºŒä¸‹ä¸€ç­†ï¼
                        st.warning(f"âš ï¸ ç¬¬ {i+1} ç­†è³‡æ–™ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼Œå·²è·³éï¼š{inner_e}")
                        results_list.append({"å…¬å¸åç¨±": title, "å‚™è¨»": "ç³»çµ±è·³é", "ç¶²å€": url})
                        
                    # æ›´æ–°é€²åº¦æ¢
                    progress_bar.progress((i + 1) / len(search_results))
                    time.sleep(0.5)

                status_box.update(label="ğŸ‰ ä»»å‹™å…¨éƒ¨å®Œæˆï¼", state="complete", expanded=False)
                
                if results_list:
                    df = pd.DataFrame(results_list)
                    # ç¢ºä¿æ¬„ä½å­˜åœ¨
                    cols = ["å…¬å¸åç¨±", "é›»è©±", "Email", "è³‡æ–™ä¾†æº", "ç¶²å€", "å‚™è¨»"]
                    for c in cols:
                        if c not in df.columns: df[c] = ""
                    df = df[cols]

                    st.dataframe(df)
                    
                    excel_file = "leads_stable.xlsx"
                    df.to_excel(excel_file, index=False)
                    with open(excel_file, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel", f, file_name="å®¢æˆ¶åå–®_ç©©å®šç‰ˆ.xlsx")

        except Exception as e:
            st.error(f"æœå°‹éšæ®µç™¼ç”Ÿåš´é‡éŒ¯èª¤ï¼š{e}")