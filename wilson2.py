import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import time
import requests
import re
from urllib.parse import urljoin, urlparse
from tavily import TavilyClient

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="è¶…ç´šæ¥­å‹™é–‹ç™¼åŠ©æ‰‹ (æ·±åº¦æŒ–æ˜ç‰ˆ)", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ å…¨è‡ªå‹•å®¢æˆ¶åå–®æœé›†å™¨ (è‡ªå‹•è¿½è¹¤è¯çµ¡é é¢ç‰ˆ)")
st.markdown("""
### ğŸš€ å‡ç´šåŠŸèƒ½ï¼šæ·±åº¦æŒ–æ˜ (Deep Crawl)
ä½ çŒœå°äº†ï¼ä¹‹å‰åªçˆ¬é¦–é å®¹æ˜“æ¼è³‡æ–™ã€‚
ç¾åœ¨ï¼Œå¦‚æœé¦–é æ‰¾ä¸åˆ° Emailï¼Œç¨‹å¼æœƒ**è‡ªå‹•å°‹æ‰¾ä¸¦é»æ“Š**ã€Œè¯çµ¡æˆ‘å€‘ã€æˆ–ã€ŒContactã€é é¢ï¼ŒæŠŠè—åœ¨å…§é çš„è³‡æ–™æŒ–å‡ºä¾†ï¼
""")

# --- 2. å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    if "GEMINI_API_KEY" in st.secrets:
        gemini_api_key = st.secrets["GEMINI_API_KEY"]
        st.success("âœ… å·²è®€å– Gemini Key")
    else:
        gemini_api_key = st.text_input("è¼¸å…¥ Gemini API Key", type="password")

    if "TAVILY_API_KEY" in st.secrets:
        tavily_api_key = st.secrets["TAVILY_API_KEY"]
        st.success("âœ… å·²è®€å– Tavily Key")
    else:
        tavily_api_key = st.text_input("è¼¸å…¥ Tavily API Key", type="password")

    num_results = st.slider("æœå°‹æ•¸é‡", 3, 20, 5) 
    debug_mode = st.toggle("é¡¯ç¤ºå¾Œå°è™•ç†éç¨‹", value=True)

# --- 3. æ ¸å¿ƒå·¥å…· ---

def get_root_url(url):
    """ å¼·åˆ¶è½‰å›é¦–é  """
    if not url: return ""
    try:
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"
    except:
        return url

def find_contact_link(markdown_text, root_url):
    """
    å¾ Jina å›å‚³çš„ Markdown ä¸­å°‹æ‰¾ã€Œè¯çµ¡æˆ‘å€‘ã€çš„é€£çµ
    æ ¼å¼é€šå¸¸æ˜¯: [Link Text](URL)
    """
    # å°‹æ‰¾åŒ…å« "è¯çµ¡", "Contact", "About", "é—œæ–¼" çš„é€£çµ
    links = re.findall(r'\[(.*?)\]\((.*?)\)', markdown_text)
    
    keywords = ["è¯çµ¡", "contact", "about", "é—œæ–¼", "support"]
    
    for text, link in links:
        for kw in keywords:
            if kw in text.lower():
                # è™•ç†ç›¸å°è·¯å¾‘ (ä¾‹å¦‚ /contact.html è½‰ç‚º https://abc.com/contact.html)
                full_link = urljoin(root_url, link)
                return full_link, text
    return None, None

def fetch_content_smart(url, fallback_content=""):
    """ 
    æ™ºæ…§æŠ“å–æµç¨‹ï¼š
    1. æŠ“é¦–é 
    2. å¦‚æœé¦–é æ²’ Emailï¼Œæ‰¾ Contact é€£çµ
    3. æŠ“ Contact é é¢
    """
    if fallback_content is None: fallback_content = ""
    
    combined_content = ""
    source_log = []

    # --- æ­¥é©Ÿ 1: æŠ“é¦–é  ---
    root_url = get_root_url(url)
    jina_url = f"https://r.jina.ai/{root_url}"
    
    try:
        resp = requests.get(jina_url, timeout=10)
        if resp.status_code == 200 and len(resp.text) > 200:
            homepage_text = resp.text
            combined_content += f"\n=== é¦–é å…§å®¹ ===\n{homepage_text[:15000]}"
            source_log.append("é¦–é ")
            
            # --- æ­¥é©Ÿ 2: æª¢æŸ¥æ˜¯å¦éœ€è¦æ·±åº¦æŒ–æ˜ ---
            # å¦‚æœé¦–é æ²’æŠ“åˆ° Emailï¼Œå˜—è©¦æ‰¾é€£çµ
            if "@" not in homepage_text:
                contact_link, link_text = find_contact_link(homepage_text, root_url)
                
                if contact_link:
                    source_log.append(f"è¿½è¹¤å…§é ({link_text})")
                    # æŠ“å–å…§é 
                    jina_contact_url = f"https://r.jina.ai/{contact_link}"
                    resp_inner = requests.get(jina_contact_url, timeout=10)
                    if resp_inner.status_code == 200:
                        combined_content += f"\n=== å…§é ({link_text}) ===\n{resp_inner.text[:15000]}"
        else:
            # Jina å¤±æ•—ï¼Œä½¿ç”¨ Tavily åº«å­˜
            if len(fallback_content) > 50:
                combined_content = fallback_content
                source_log.append("åº«å­˜")
                
    except:
        # ç™¼ç”ŸéŒ¯èª¤ï¼Œé€€å›ä½¿ç”¨åº«å­˜
        if len(fallback_content) > 50:
            combined_content = fallback_content
            source_log.append("åº«å­˜(æ•‘æ´)")

    return combined_content, " + ".join(source_log)

def regex_backup(text):
    """ æš´åŠ›æƒæ """
    if not text: return [], []
    try:
        text_clean = " ".join(text.split())
        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text_clean)
        phones = re.findall(r'(?:\(?0\d{1,2}\)?[\s\-]?)?\d{3,4}[\s\-]?\d{3,4}', text_clean)
        valid_phones = [p for p in list(set(phones)) if len(re.sub(r'\D', '', p)) >= 8]
        return list(set(emails)), valid_phones
    except:
        return [], []

# --- 4. AI åˆ†æå‡½æ•¸ ---

def extract_contact_info(content, url, model):
    emails, phones = regex_backup(content)
    
    try:
        backup_info = f"Email: {emails[:3]}, é›»è©±: {phones[:5]}"
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–æ©Ÿå™¨äººã€‚è«‹åˆ†æç¶²é å…§å®¹æ‰¾å‡ºè¯çµ¡æ–¹å¼ã€‚
        æ³¨æ„ï¼šå…§å®¹å¯èƒ½åŒ…å«é¦–é å’Œè¯çµ¡æˆ‘å€‘å…§é çš„è³‡æ–™ã€‚
        
        ç¶²å€ï¼š{url}
        åƒè€ƒæ•¸æ“šï¼š{backup_info}

        ç¶²é å…§å®¹æ‘˜è¦ï¼š
        {content[:40000]} 
        
        è«‹å›å‚³ JSONï¼š
        {{
            "å…¬å¸åç¨±": "...", 
            "é›»è©±": "...", 
            "Email": "...",
            "å‚³çœŸ": "...",
            "ç¶²å€": "{url}"
        }}
        """
        response = model.generate_content(prompt)
        txt = response.text.strip()
        
        if "```json" in txt:
            txt = txt.split("```json")[1].split("```")[0]
        elif "```" in txt:
            txt = txt.split("```")[0]
            
        data = json.loads(txt)

        if (not data.get("Email") or data.get("Email") == "None") and emails:
            data["Email"] = emails[0]
        if (not data.get("é›»è©±") or data.get("é›»è©±") == "None") and phones:
            data["é›»è©±"] = phones[0]

        return data

    except:
        return {
            "å…¬å¸åç¨±": "ERROR", 
            "é›»è©±": phones[0] if phones else "", 
            "Email": emails[0] if emails else "", 
            "å‚³çœŸ": "",
            "ç¶²å€": url
        }

# --- 5. ä¸»ç¨‹å¼ ---
keyword = st.text_input("ğŸ” è«‹è¼¸å…¥æœå°‹é—œéµå­—", value="å»¢æ°´å›æ”¶ç³»çµ± å…¬å¸")

if st.button("é–‹å§‹æœå°‹èˆ‡åˆ†æ"):
    if not gemini_api_key or not tavily_api_key:
        st.error("âŒ è«‹è¼¸å…¥ API Key")
    else:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        tavily = TavilyClient(api_key=tavily_api_key)
        
        status_box = st.status("ğŸš€ å•Ÿå‹•æ·±åº¦çˆ¬èŸ²...", expanded=True)
        results_list = []
        
        try:
            status_box.write(f"æ­£åœ¨æœå°‹ï¼š{keyword}...")
            response = tavily.search(query=keyword, max_results=num_results, include_raw_content=True)
            search_results = response.get('results', [])
            
            if not search_results:
                status_box.error("æ‰¾ä¸åˆ°ç¶²å€")
            else:
                progress_bar = st.progress(0)
                
                for i, item in enumerate(search_results):
                    try:
                        url = item.get('url', 'ç„¡ç¶²å€')
                        title = item.get('title', 'ç„¡æ¨™é¡Œ')
                        tavily_raw = item.get('raw_content') or ""
                        
                        status_box.write(f"({i+1}/{len(search_results)}) åˆ†æï¼š{title}")
                        
                        # --- é—œéµè®Šæ›´ï¼šä½¿ç”¨æ–°çš„ fetch å‡½æ•¸ ---
                        content, source_log = fetch_content_smart(url, fallback_content=tavily_raw)
                        
                        if debug_mode:
                            # è®“ä½ çŸ¥é“ç¨‹å¼æœ‰æ²’æœ‰è·‘å»æŠ“å…§é 
                            with st.expander(f"ğŸ” è¿½è¹¤è·¯å¾‘: {source_log}"):
                                st.text(f"è³‡æ–™é•·åº¦: {len(content)}")
                        
                        if len(content) > 50:
                            data = extract_contact_info(content, url, model)
                            
                            name = str(data.get("å…¬å¸åç¨±", ""))
                            if name == "ERROR" or "å¤±æ•—" in name or name == "None":
                                data["å…¬å¸åç¨±"] = title
                            
                            results_list.append(data)
                        else:
                            pass
                            
                    except:
                        pass
                        
                    progress_bar.progress((i + 1) / len(search_results))
                    # å› ç‚ºå¤šçˆ¬ä¸€é ï¼Œç¦®è²Œæ€§æš«åœç¨å¾®ä¹…ä¸€é»é»
                    time.sleep(1)

                status_box.update(label="ğŸ‰ æ·±åº¦æœé›†å®Œæˆï¼", state="complete", expanded=False)
                
                if results_list:
                    df = pd.DataFrame(results_list)
                    cols = ["å…¬å¸åç¨±", "é›»è©±", "Email", "å‚³çœŸ", "ç¶²å€"]
                    
                    for c in cols:
                        if c not in df.columns: df[c] = ""
                    df = df[cols]

                    st.dataframe(df)
                    
                    excel_file = "leads_deep.xlsx"
                    df.to_excel(excel_file, index=False)
                    with open(excel_file, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel åå–®", f, file_name=f"{keyword}_æ·±åº¦åå–®.xlsx")

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")